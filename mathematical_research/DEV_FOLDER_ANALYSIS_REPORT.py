#!/usr/bin/env python3
"""
üèóÔ∏è DEV FOLDER ANALYSIS REPORT
=============================

COMPREHENSIVE ANALYSIS OF THE DEVELOPMENT ENVIRONMENT
IDENTIFYING MISSING COMPONENTS AND IMPROVEMENT OPPORTUNITIES

This report analyzes the current dev folder structure and identifies
what's missing to create a complete, professional development environment.
"""

import os
import json
from pathlib import Path
from datetime import datetime

class DevFolderAnalyzer:
    """Analyzes the development folder for completeness and missing components"""

    def __init__(self, root_path="/Users/coo-koba42/dev"):
        self.root_path = Path(root_path)
        self.analysis_results = {}
        self.missing_components = []
        self.recommendations = []

    def run_complete_analysis(self):
        """Run comprehensive analysis of the dev folder"""
        print("üîç ANALYZING DEV FOLDER COMPLETENESS...")
        print("=" * 80)

        self.analyze_basic_structure()
        self.analyze_configuration_files()
        self.analyze_package_management()
        self.analyze_deployment_setup()
        self.analyze_development_tools()
        self.analyze_documentation()
        self.analyze_testing_infrastructure()
        self.analyze_ci_cd_setup()
        self.analyze_security_setup()
        self.analyze_monitoring_logging()
        self.analyze_backup_recovery()

        self.generate_recommendations()
        self.generate_action_plan()

        return self.create_final_report()

    def analyze_basic_structure(self):
        """Analyze basic folder structure"""
        print("üìÅ Analyzing basic folder structure...")

        required_dirs = [
            'src', 'tests', 'docs', 'scripts', 'config', 'tools',
            'examples', 'templates', 'assets', 'build', 'dist'
        ]

        existing_dirs = []
        for item in os.listdir(self.root_path):
            if os.path.isdir(self.root_path / item) and not item.startswith('.'):
                existing_dirs.append(item)

        missing_dirs = [d for d in required_dirs if d not in existing_dirs]

        self.analysis_results['basic_structure'] = {
            'existing_directories': existing_dirs,
            'missing_directories': missing_dirs,
            'total_directories': len(existing_dirs),
            'structure_score': len(existing_dirs) / len(required_dirs)
        }

        if missing_dirs:
            self.missing_components.extend([f"üìÅ Missing directory: {d}" for d in missing_dirs])

    def analyze_configuration_files(self):
        """Analyze configuration files"""
        print("‚öôÔ∏è Analyzing configuration files...")

        config_files = [
            'pyproject.toml', 'setup.py', 'requirements.txt', 'Pipfile', 'poetry.lock',
            'package.json', 'tsconfig.json', 'webpack.config.js', '.eslintrc.js',
            'Dockerfile', 'docker-compose.yml', 'Makefile', '.pre-commit-config.yaml'
        ]

        existing_configs = []
        for config in config_files:
            if (self.root_path / config).exists():
                existing_configs.append(config)

        missing_configs = [c for c in config_files if c not in existing_configs]

        # Check for existing requirements.txt
        req_file = self.root_path / 'requirements.txt'
        if req_file.exists():
            with open(req_file, 'r') as f:
                dep_count = len([line for line in f if line.strip() and not line.startswith('#')])
        else:
            dep_count = 0

        self.analysis_results['configuration'] = {
            'existing_configs': existing_configs,
            'missing_configs': missing_configs,
            'dependency_count': dep_count,
            'config_score': len(existing_configs) / len(config_files)
        }

        if missing_configs:
            self.missing_components.extend([f"‚öôÔ∏è Missing config: {c}" for c in missing_configs])

    def analyze_package_management(self):
        """Analyze package management setup"""
        print("üì¶ Analyzing package management...")

        package_managers = ['pip', 'poetry', 'npm', 'yarn', 'pnpm']
        detected_managers = []

        if (self.root_path / 'requirements.txt').exists():
            detected_managers.append('pip')
        if (self.root_path / 'pyproject.toml').exists() and (self.root_path / 'poetry.lock').exists():
            detected_managers.append('poetry')
        if (self.root_path / 'package.json').exists():
            detected_managers.append('npm')
            if (self.root_path / 'yarn.lock').exists():
                detected_managers.append('yarn')
            elif (self.root_path / 'pnpm-lock.yaml').exists():
                detected_managers.append('pnpm')

        self.analysis_results['package_management'] = {
            'detected_managers': detected_managers,
            'primary_manager': detected_managers[0] if detected_managers else None,
            'has_lock_files': any((self.root_path / f'{pm}.lock').exists() for pm in ['poetry', 'yarn', 'package-lock'])
        }

    def analyze_deployment_setup(self):
        """Analyze deployment and containerization setup"""
        print("üöÄ Analyzing deployment setup...")

        deployment_files = [
            'Dockerfile', 'docker-compose.yml', '.dockerignore',
            'kubernetes/', 'helm/', 'terraform/',
            'serverless.yml', 'vercel.json', 'netlify.toml'
        ]

        existing_deployment = []
        for deploy_file in deployment_files:
            if (self.root_path / deploy_file).exists():
                existing_deployment.append(deploy_file)

        self.analysis_results['deployment'] = {
            'existing_deployment_files': existing_deployment,
            'has_docker': 'Dockerfile' in existing_deployment,
            'has_docker_compose': 'docker-compose.yml' in existing_deployment,
            'has_kubernetes': any('kubernetes' in d for d in existing_deployment),
            'deployment_score': len(existing_deployment) / len(deployment_files)
        }

        if not any('Dockerfile' in d for d in existing_deployment):
            self.missing_components.append("üê≥ Missing Dockerfile for containerization")

    def analyze_development_tools(self):
        """Analyze development tools and utilities"""
        print("üõ†Ô∏è Analyzing development tools...")

        dev_tools = [
            'scripts/', 'tools/', '.pre-commit-config.yaml',
            '.editorconfig', '.vscode/', '.idea/',
            '.devcontainer/', 'dev-requirements.txt'
        ]

        existing_tools = []
        for tool in dev_tools:
            if (self.root_path / tool.rstrip('/')).exists():
                existing_tools.append(tool)

        self.analysis_results['dev_tools'] = {
            'existing_tools': existing_tools,
            'has_scripts_dir': 'scripts/' in existing_tools,
            'has_tools_dir': 'tools/' in existing_tools,
            'has_precommit': '.pre-commit-config.yaml' in existing_tools,
            'has_editorconfig': '.editorconfig' in existing_tools,
            'tools_score': len(existing_tools) / len(dev_tools)
        }

    def analyze_documentation(self):
        """Analyze documentation completeness"""
        print("üìö Analyzing documentation...")

        doc_files = [
            'README.md', 'CHANGELOG.md', 'CONTRIBUTING.md', 'LICENSE',
            'docs/', 'API.md', 'ARCHITECTURE.md', 'DEPLOYMENT.md'
        ]

        existing_docs = []
        for doc in doc_files:
            if (self.root_path / doc).exists():
                existing_docs.append(doc)

        readme_files = list(self.root_path.glob('README*'))
        changelog_files = list(self.root_path.glob('CHANGELOG*'))
        license_files = list(self.root_path.glob('LICENSE*'))

        self.analysis_results['documentation'] = {
            'existing_docs': existing_docs,
            'readme_files': [f.name for f in readme_files],
            'changelog_files': [f.name for f in changelog_files],
            'license_files': [f.name for f in license_files],
            'has_docs_dir': 'docs/' in existing_docs,
            'documentation_score': len(existing_docs) / len(doc_files)
        }

    def analyze_testing_infrastructure(self):
        """Analyze testing infrastructure"""
        print("üß™ Analyzing testing infrastructure...")

        test_patterns = [
            'tests/', 'test_*.py', '*_test.py', '__tests__/',
            'spec/', 'conftest.py', 'pytest.ini', 'tox.ini'
        ]

        test_files = []
        for pattern in test_patterns:
            matches = list(self.root_path.glob(pattern))
            test_files.extend([f.name for f in matches])

        test_files = list(set(test_files))  # Remove duplicates

        # Count actual test files
        test_count = len(list(self.root_path.rglob('test_*.py'))) + len(list(self.root_path.rglob('*_test.py')))

        self.analysis_results['testing'] = {
            'test_files': test_files,
            'test_count': test_count,
            'has_test_dir': 'tests' in os.listdir(self.root_path),
            'has_conftest': 'conftest.py' in test_files,
            'has_pytest_config': any('pytest' in f for f in test_files),
            'testing_score': min(1.0, len(test_files) / 10)  # Normalize to 0-1
        }

    def analyze_ci_cd_setup(self):
        """Analyze CI/CD setup"""
        print("üîÑ Analyzing CI/CD setup...")

        ci_cd_files = [
            '.github/workflows/', '.gitlab-ci.yml', 'Jenkinsfile',
            'azure-pipelines.yml', 'bitbucket-pipelines.yml',
            '.travis.yml', '.circleci/', 'buildspec.yml'
        ]

        existing_ci = []
        for ci_file in ci_cd_files:
            if (self.root_path / ci_file.rstrip('/')).exists():
                existing_ci.append(ci_file)

        self.analysis_results['ci_cd'] = {
            'existing_ci_files': existing_ci,
            'has_github_actions': '.github/workflows/' in existing_ci,
            'has_gitlab_ci': '.gitlab-ci.yml' in existing_ci,
            'has_jenkins': 'Jenkinsfile' in existing_ci,
            'ci_score': len(existing_ci) / len(ci_cd_files)
        }

        if not existing_ci:
            self.missing_components.append("üîÑ Missing CI/CD pipeline configuration")

    def analyze_security_setup(self):
        """Analyze security setup"""
        print("üîí Analyzing security setup...")

        security_files = [
            '.secrets/', 'security/', '.env.example',
            'SECURITY.md', '.snyk', 'codeql/', 'dependabot.yml'
        ]

        existing_security = []
        for sec_file in security_files:
            if (self.root_path / sec_file.rstrip('/')).exists():
                existing_security.append(sec_file)

        # Check for common security issues
        has_env_files = list(self.root_path.glob('.env*'))
        has_secrets = list(self.root_path.glob('*secret*'))

        self.analysis_results['security'] = {
            'existing_security_files': existing_security,
            'env_files': [f.name for f in has_env_files],
            'secrets_files': [f.name for f in has_secrets],
            'has_security_md': 'SECURITY.md' in existing_security,
            'has_env_example': '.env.example' in existing_security,
            'security_score': len(existing_security) / len(security_files)
        }

    def analyze_monitoring_logging(self):
        """Analyze monitoring and logging setup"""
        print("üìä Analyzing monitoring and logging...")

        monitoring_files = [
            'monitoring/', 'logs/', '.logrotate',
            'prometheus/', 'grafana/', 'datadog/',
            'newrelic/', 'sentry/', 'logstash/'
        ]

        existing_monitoring = []
        for mon_file in monitoring_files:
            if (self.root_path / mon_file.rstrip('/')).exists():
                existing_monitoring.append(mon_file)

        self.analysis_results['monitoring'] = {
            'existing_monitoring_files': existing_monitoring,
            'has_monitoring_dir': 'monitoring/' in existing_monitoring,
            'has_logs_dir': 'logs/' in existing_monitoring,
            'has_prometheus': 'prometheus/' in existing_monitoring,
            'monitoring_score': len(existing_monitoring) / len(monitoring_files)
        }

    def analyze_backup_recovery(self):
        """Analyze backup and recovery setup"""
        print("üíæ Analyzing backup and recovery...")

        backup_files = [
            'backups/', '.backup/', 'backup.sh',
            'restore.sh', 'disaster-recovery.md'
        ]

        existing_backup = []
        for backup_file in backup_files:
            if (self.root_path / backup_file).exists():
                existing_backup.append(backup_file)

        self.analysis_results['backup'] = {
            'existing_backup_files': existing_backup,
            'has_backup_dir': 'backups/' in existing_backup,
            'has_backup_script': 'backup.sh' in existing_backup,
            'has_restore_script': 'restore.sh' in existing_backup,
            'backup_score': len(existing_backup) / len(backup_files)
        }

    def generate_recommendations(self):
        """Generate improvement recommendations"""
        print("üí° Generating recommendations...")

        self.recommendations = [
            # Configuration & Packaging
            "üì¶ Add pyproject.toml for modern Python packaging",
            "üê≥ Add Dockerfile and docker-compose.yml for containerization",
            "üîß Add Makefile for common development tasks",
            "üìã Add .pre-commit-config.yaml for code quality enforcement",

            # Development Tools
            "üõ†Ô∏è Create scripts/ directory for automation scripts",
            "‚öôÔ∏è Add .editorconfig for consistent coding styles",
            "üîß Add dev-requirements.txt for development dependencies",

            # Documentation
            "üìö Add comprehensive README.md with setup instructions",
            "üìã Create CONTRIBUTING.md for contribution guidelines",
            "üìú Add LICENSE file for open source compliance",
            "üèóÔ∏è Create ARCHITECTURE.md documenting system design",

            # Testing & Quality
            "üß™ Expand testing infrastructure with more comprehensive test suites",
            "üîç Add code coverage reporting and quality metrics",
            "üö® Add static analysis tools (flake8, mypy, black)",

            # CI/CD & Deployment
            "üîÑ Add GitHub Actions workflows for CI/CD",
            "üê≥ Implement containerization strategy",
            "‚òÅÔ∏è Add deployment configurations for cloud platforms",

            # Security & Monitoring
            "üîí Add security scanning and vulnerability management",
            "üìä Implement comprehensive monitoring and alerting",
            "üìù Add structured logging with log aggregation",

            # Project Management
            "üìä Add project management tools and issue tracking",
            "üéØ Create project roadmap and milestone planning",
            "üë• Add team collaboration and communication guidelines"
        ]

    def generate_action_plan(self):
        """Generate prioritized action plan"""
        self.action_plan = {
            'immediate': [
                "Add pyproject.toml for package management",
                "Create comprehensive README.md",
                "Add Dockerfile for containerization",
                "Implement basic CI/CD with GitHub Actions"
            ],
            'short_term': [
                "Set up pre-commit hooks for code quality",
                "Add comprehensive testing framework",
                "Implement monitoring and logging",
                "Create deployment automation"
            ],
            'medium_term': [
                "Add security scanning and compliance",
                "Implement backup and disaster recovery",
                "Create comprehensive documentation",
                "Set up development environment automation"
            ],
            'long_term': [
                "Implement advanced monitoring and alerting",
                "Add performance optimization tools",
                "Create comprehensive API documentation",
                "Implement automated scaling strategies"
            ]
        }

    def create_final_report(self):
        """Create comprehensive final report"""
        report = {
            'analysis_timestamp': datetime.now().isoformat(),
            'analysis_results': self.analysis_results,
            'missing_components': self.missing_components,
            'recommendations': self.recommendations,
            'action_plan': self.action_plan,
            'overall_score': self.calculate_overall_score(),
            'priority_matrix': self.create_priority_matrix()
        }

        return report

    def calculate_overall_score(self):
        """Calculate overall development environment score"""
        scores = []
        for category, data in self.analysis_results.items():
            if 'score' in data:
                scores.append(data['score'])

        return sum(scores) / len(scores) if scores else 0

    def create_priority_matrix(self):
        """Create priority matrix for improvements"""
        return {
            'critical': ['pyproject.toml', 'README.md', 'Dockerfile', 'basic CI/CD'],
            'high': ['testing infrastructure', 'security setup', 'documentation'],
            'medium': ['monitoring', 'deployment automation', 'code quality tools'],
            'low': ['advanced features', 'performance optimization', 'scaling']
        }

def main():
    """Main function to run the dev folder analysis"""
    print("üèóÔ∏è DEV FOLDER ANALYSIS REPORT")
    print("============================")
    print("Analyzing the development environment for completeness and missing components")
    print("=" * 80)

    analyzer = DevFolderAnalyzer()
    report = analyzer.run_complete_analysis()

    # Display results
    print("\nüìä ANALYSIS RESULTS:")
    print("=" * 50)
    print(f"üìà Overall development score: {report['overall_score']:.3f}")
    print(f"üìÅ Total directories analyzed: {len(report['analysis_results'])}")
    print(f"‚ö†Ô∏è Missing components identified: {len(report['missing_components'])}")

    print("\nüö® MISSING COMPONENTS:")
    for component in report['missing_components'][:10]:  # Show first 10
        print(f"   ‚Ä¢ {component}")
    if len(report['missing_components']) > 10:
        print(f"   ... and {len(report['missing_components']) - 10} more")

    print("\nüí° KEY RECOMMENDATIONS:")
    for rec in report['recommendations'][:10]:  # Show first 10
        print(f"   ‚Ä¢ {rec}")
    if len(report['recommendations']) > 10:
        print(f"   ... and {len(report['recommendations']) - 10} more")

    print("\nüéØ IMMEDIATE ACTION ITEMS:")
    for action in report['action_plan']['immediate']:
        print(f"   ‚úÖ {action}")

    # Save detailed report
    report_file = f"dev_folder_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2, default=str)

    print(f"\nüìÑ Detailed report saved to: {report_file}")
    print("\nüèÜ ANALYSIS COMPLETE - Ready to enhance the development environment!")

if __name__ == "__main__":
    main()
